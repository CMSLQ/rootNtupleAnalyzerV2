

This file describes how to process a full dataset (and/or several datasets)
of already-created roottuples (generally stored on CASTOR) using rootNtupleAnalyzerV2
and running PARALLEL jobs on LXPLUS BATCH.

The final output will be a root file (with plots rescaled by a given integrated luminosity)
and a .dat file (with the selection efficiencies) for each processed dataset.
To do so, the scripts in the directory rootNtupleAnalyzerV2/scripts/ are used.
Output files are created on a local directory.

NOTE: the description/location of already-created roottuples is at
      https://twiki.cern.ch/twiki/bin/view/CMS/ExoticaLeptoquarkRootTuplesV2Location2010
      while the instructions to create the roottuples are at
      https://twiki.cern.ch/twiki/bin/view/CMS/ExoticaLeptoquarkShiftMakeRootTuplesV2

#############
INSTRUCTIONS:
#############

#################################################################################
1) Download, compile and test locally the rootNtupleAnalyzerV2 code following the
   instructions at rootNtupleAnalyzerV2/README

#################################################################################
pre-2) This is needed to use correctly the python libraries for PYROOT
       without conflicts. The python environment will be set using
       the CMSSW scripts ("cmsenv" as described below)

       Somewhere create a CMSSW release or use an existing one:
	 scramv1 project CMSSW CMSSW_3_5_7
	 cd CMSSW_3_5_7/src
	 cmsenv (now the CMSSW ROOT and PYTHON environment variables are set)
	 cd - (to came back in the workdir)

#################################################################################
2) Create a global list containing the lists (one list for each dataset) of root
   files with:

   ./scripts/createList.py

   You'll be asked for arguments.
   An example is:

   ./scripts/createList.py -m root -i /castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412 -o config

   which creates a global list config/inputListAllCurrent.txt containing one list for each dataset
	config/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-280_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-300_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-320_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-340_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-370_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-400_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-450_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-500_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt
	config/LQToUE_M-600_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt

   Each single-dataset list contains the pointers to the CASTOR location of the roottuple files to be processed,
   e.g. config/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.txt contains:
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_1_1.root
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_2_1.root
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_3_1.root
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_4_1.root
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_5_1.root
	rfio:/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412/LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_6_1.root

#################################################################################
3) Run the rootNtupleAnalyzer over all the datasets (i.e. lists)
   running multiple parallel jobs on the LXPLUS BATCH system:

   ./scripts/launchAnalysis_batch.pl

   You'll be asked for arguments.
   An example is:

   ./scripts/launchAnalysis_batch.pl -i config/inputListAllCurrent.txt -n rootTupleTree/tree -c config/cutTable.txt -o data/output -j 30 -q 1nh -w 5 | tee temp.log

   NOTE: the argument "-j 30" means that 30 jobs will be submitted for each dataset.
   However, if the number of roottuple files, N, for a dataset is less than 30, then 30 will be
   automatically replaced by N, so that no more than one job per roottuple file will be submitted.
   If you want to look quickly how many files you have for each dataset you can run
     for file in `cat config/inputListAllCurrent.txt`; do wc $file; done
   and look at the first number on each output line.

   The option "-w 5" (not mandatory) put a <sleep> command of 5 seconds after the submission of each dataset.
   This is needed recently since the rate of lxbatch submissions cannot exceed some limit.
   This value might need to be tuned depending on the size of the dataset.
   5 seconds is found to be a good cut for the moment.

   The command above creates a directory for each dataset in data/output/, e.g.
   data/output/analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO/
   Each of such directories will contain the subdirs:
   input/  log/  output/  src/

   One output .root and .dat files for each submitted job will be created (gererally within minutes if you
   have submitted a sufficient number of jobs) in the output/ subdirectory.

   NOTE: in order to check the status of the jobs, run the command
         bjobs
         Other useful commands (see their man page) are
         bpeek
         bkill

   An example of the content of the output/ subdirectory is:
     [lxplus218] ls data/output/analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO/output/
        analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_0.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_0.root
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_1.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_1.root
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_2.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_2.root
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_3.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_3.root
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_4.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_4.root
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_5.dat
	analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO_5.root

   where "analysisClass_eejjSample" is the name of the actual code used for the analysis.

#####################################################################################
4) Combine .root and .dat files of each jobs into a single .root and .dat file
   for each dataset using

   ./scripts/check_combine_output_batch.py

   You'll be asked for arguments.
   An example is:

   ./scripts/check_combine_output_batch.py -i `pwd`/config/inputListAllCurrent.txt -c analysisClass_eejjSample -d `pwd`/data/output -o `pwd`/data/output -q 1nh

   If all jobs were OK, message "=== All jobs successfull!!! ===" will appear.

   If any job failed, a file ToBeResubmitted.list will be created.
   To resubmit the failed jobs do:
     source ToBeResubmitted.list
   then try again ./scripts/check_combine_output_batch.py

   With the above example command, the output .root and .dat file of each dataset will be
   in the directory:
     data/output/
   for example:
     analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.root
     analysisClass_eejjSample___LQToUE_M-250_7TeV-pythia6__Spring10-START3X_V26-v1__GEN-SIM-RECO.dat

#####################################################################################
5) Combine histograms and tables for different datasets (rescaling for cross section)

   Create a file with the cross section (in pb) for each dataset. An example is already available at
     config/xsection_pb_default.txt :

	/Exotica_LQtoCMu_M250/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 5.82
	/Exotica_LQtoCMu_M400/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 0.432
	/Exotica_LQtoUE_M250/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 5.82
	/Exotica_LQtoUE_M400/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 0.432
	/TTJets-madgraph/Summer08_IDEAL_V9_v2/GEN-SIM-RECO 317
	/ZJets-madgraph/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 3700
	/WJets-madgraph/Summer08_IDEAL_V9_v1/GEN-SIM-RECO 40000

   Create a file with the name of the SAMPLE for which you want the final plots and efficiency tables.
   An example is
     config/sampleListForMerging.txt :

  	LQtoUE_M250 Exotica_LQtoUE_M250
  	LQtoUE_M400 Exotica_LQtoUE_M400
  	Z           Zee  ZJets-madgraph
  	QCD         HerwigQCDPt  PYTHIA8PhotonJetPt  QCDDiJetPt
  	TTBAR       TTJets-madgraph
  	QCDTTBAR    HerwigQCDPt  PYTHIA8PhotonJetPt  QCDDiJetPt TTJets-madgraph
  	ALLBKG      Zee  ZJets-madgraph HerwigQCDPt  PYTHIA8PhotonJetPt  QCDDiJetPt TTJets-madgraph

   The first name of each row is the name of the SAMPLE (you decide it).
   The other elements of the row are strings that will be used to find the datasets
   from the list which must be included in that SAMPLE.
   If at least one of the strings matches with the name of a dataset
   (i.e. Exotica_LQtoUE_M400 matches with /Exotica_LQtoUE_M400/Summer08_IDEAL_V9_v1/GEN-SIM-RECO),
   that dataset will be assumed as part of the SAMPLE. Plots and tables from datasets
   associated to the same SAMPLE will be merged (rescaling for cross section).

   Two different python scripts are used:

     ./scripts/combineTablesTemplate.py (for tables)
     ./scripts/combinePlotsTemplate.py (for histograms)

   You'll be asked for arguments, and be prompted with an example usage.



###################################################################################

NOTE: to run on several datasets with roottuples stored in DIFFERENT CASTOR LOCATIONS
      one could do:

Create lists:

## Electron/EG + Electron skim

  ./scripts/createList.py \
    -m root \
    -i \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_low_mass_20100604_213652 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-eejj_20100518_231412 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-enujj_low_mass_20100608_175052 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-LQ-enujj_20100519_011206 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-TTbar_SingleTop_VV_20100519_011910 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-Z_plus_Jets_20100520_171604 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-W_plus_Jets_20100521_141022 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-WW_ZZ_WZ_20100612_133148 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-TTbar_ZeeJet_Pythia6_20100707_214138 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-08-MC-ZJet-madgraph_20100828_021017 \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-EG-Run2010A-Sep17ReReco_v2-132440-144114_20101006_194357 \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-Electron-Run2010B-PromptReco-v2-146428-146644_20101006_162408 \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-Electron-Run2010B-PromptReco-v2-146804-147114_20101009_001302 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-Electron-Run2010B-PromptReco-v2_146511-146513_147115-147454_20101018_051044 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-01-02-DATA-Electron-Run2010B-PromptReco-v2_147757-148058_20101025_012008 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-01-02-DATA-Electron-Run2010B-PromptReco-v2_147754-148031_148822-148864_20101101_014243 \
-o config/ElectronSkim


## Photon/EG + Supercluster skim

 ./scripts/createList.py \
    -m root \
    -i \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-SC_Skim-EG-Run2010A-Sep17ReReco_v2-132440-144114_20101007_124915 \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-01-01-DATA-SC_Skim-Photon-Run2010B-PromptReco-v2-146428-146644_20101007_144045 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-01-02-DATA-Photon-Run2010B-PromptReco-v2_146804-148058_20101025_014657 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-01-02-DATA-Photon-Run2010B-PromptReco-v2_147754-148031_148822-148864_20101101_015743 \
-o config/PhotonSkim


//---------------------------
OLD DATA:
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Jun14thReReco_v1_132440-137028_20100719_165009 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Run2010A-Jul16thReReco_v2_139779-140160_20100719_181525 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Run2010A-PromptReco-v4_138564-139459_140180-140387_20100719_183025 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Run2010A-PromptReco-v4_140401-141961_20100805_023138 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Run2010A-PromptReco-v4_142035-143179_20100821_013157 \
/castor/cern.ch/user/f/ferencek/LQ/RootNtuple/RootNtuple-V00-00-12-DATA-EG-Run2010A-PromptReco-v4_143181-144114_20100907_232524 \
//---------------------------
OLD MC:
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-00-08-MC-QCDmadgraph_20100519_233358 \
/castor/cern.ch/user/s/santanas/LQ/RootNtuple/RootNtuple-V00-00-08-MC-QCDPt15_20100603_100942 \
//---------------------------


Launch the batch jobs on the total list:

  ./scripts/launchAnalysis_batch.pl -i config/inputListAllCurrent.txt -n rootTupleTree/tree -c config/cutTable.txt -o data/output -j 30 -q 1nh


Check and combine the jobs of the total list

 ./scripts/check_combine_output_batch.py -i config/inputListAllCurrent.txt -c analysisClass_eejjSample -d data/output -o data/output -q 1nh


Go to step 5) above.


###################################################################################

NOTE: old instructions for running the analyzer in local (no multiple batch jobs)
      are still at doc/howToMakeAnalysisWithRootTuples_OLD.txt

###################################################################################

RUNNING ON SEVERAL CUT FILES:

To generate several cut files (e.g. with several Mee,St cuts), the script
  ../rootNtupleMacrosV2/config/eejj/make_eejj_cutFiles.py
is available.

Also, to facilitate creating all sets of commands needed to run the analysis
on several cut files, a script
  ./scripts/writeCommandsToRunOnMoreCutFiles.sh
is available.

###################################################################################



Various stuff:

To check how many batch jobs you may want to give to the '-j' option of ./scripts/launchAnalysis_batch.pl
  for file in `cat config/inputListAllCurrent.txt`; do wc $file; done

To kill all submitted batch jobs:
  for file in `bjobs | awk '{if($1 != "JOBID") print $1}'`; do bkill $file; done

  or

  bkill -q QUEUE -u USERNAME 0 (put your lxplus username, i.e. santanas, and name of the queue, i.e. 1nh)

To see a JSON decently:
  sed 's/"1/\n"1/g' Cert_132440-136297_7TeV_StreamExpress_Collisions10_JSON.txt |sort

To see entries and abs efficiency for only a selected cut, eg sT, for every sample in the merged/rescaled efficiency file
and adding a rescaling factor:
  awk -v factor=1.0 '{if( NF==1 ) name=$1; if( $1=="sT" ) printf("%20s %20s     %f %f        %f %f \n",name,$1,$6*factor,$7*factor,$10,$11) }' ./data/output/analysisClass_eejjSample_tables.dat

and pipe it into the following to select specific samples:
  |egrep 'LQeejj_M100 | LQeejj_M200 | LQeejj_M300 | TTbar_Madgraph | ZJetAlpgen | OTHERBKG | ALLBKG | DATA' | sort
